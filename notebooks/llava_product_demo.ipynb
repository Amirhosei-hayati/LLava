{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# تشخیص و توصیف کالا با LLaVA\n",
    "این نوت‌بوک نحوه‌ی راه‌اندازی مدل LLaVA و اجرای اپلیکیشن Gradio برای تشخیص و توصیف کالاها از روی تصویر را در Google Colab نشان می‌دهد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install torch transformers accelerate safetensors gradio Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## بارگذاری مدل"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-model"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "MODEL_ID = \"llava-hf/llava-1.5-7b-hf\"\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID, use_fast=False)\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    ")\n",
    "device = next(model.parameters()).device\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## توابع کمکی برای تولید توضیح"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "helpers"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "\n",
    "DEFAULT_QUESTION = (\n",
    "    \"این محصول چیست؟ لطفاً نوع کالا، رنگ و جنس ظاهری، کاربرد اصلی و بهترین دسته‌بندی پیشنهادی برای فروشگاه آنلاین را بیان کن.\"\n",
    ")\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an e-commerce assistant that receives a product image and produces rich,\"\n",
    "    \" structured descriptions in Persian. Summaries must include: \\n1. نوع و مدل احتمالی کالا\"\n",
    "    \"\\n2. رنگ‌ها و جنس یا متریال قابل تشخیص\"\n",
    "    \"\\n3. کاربرد یا سناریوی استفاده‌ی معمول\"\n",
    "    \"\\n4. دو یا سه دسته‌بندی پیشنهادی برای وب‌سایت فروشگاهی\"\n",
    "    \"\\nIf you are uncertain, clearly mention the uncertainty and provide the closest guess.\"\n",
    ")\n",
    "\n",
    "def build_prompt(question: str) -> str:\n",
    "    sanitized_question = question.strip() or DEFAULT_QUESTION\n",
    "    return (\n",
    "        \"[INST] <<SYS>>\" + SYSTEM_PROMPT + \"<</SYS>>\\n\"\n",
    "        \"<image>\\n\"\n",
    "        + sanitized_question\n",
    "        + \"\\nپاسخ را به صورت متنی ساختارمند در چند جمله ارائه کن. [/INST]\"\n",
    "    )\n",
    "\n",
    "def generate_description(image: Image.Image, question: str = DEFAULT_QUESTION):\n",
    "    prompt = build_prompt(question)\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.inference_mode():\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=256, temperature=0.2, top_p=0.7)\n",
    "    output = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return output.split(\"[/INST]\")[-1].strip()\n",
    "\n",
    "image = Image.open(urlopen(\"https://huggingface.co/datasets/mishig/sample_images/resolve/main/shoes.png\"))\n",
    "generate_description(image)
"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## راه‌اندازی رابط Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gradio-app"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def interface_fn(image, question, temperature, top_p, max_new_tokens):\n",
    "    if image is None:\n",
    "        return \"ابتدا تصویر را بارگذاری کنید.\"\n",
    "    prompt = build_prompt(question)\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.inference_mode():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=temperature > 0,\n",
    "        )\n",
    "    output = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return output.split(\"[/INST]\")[-1].strip()\n",
    "\n",
    "demo = gr.Blocks()\n",
    "with demo:\n",
    "    gr.Markdown(\"# اپ تشخیص کالا با LLaVA\")\n",
    "    with gr.Row():\n",
    "        image_input = gr.Image(type=\"pil\", label=\"تصویر کالا\")\n",
    "        output_box = gr.Textbox(label=\"نتیجه\", lines=12)\n",
    "    question_box = gr.Textbox(value=DEFAULT_QUESTION, label=\"پرسش\")\n",
    "    temperature_slider = gr.Slider(0.0, 1.0, value=0.2, step=0.05, label=\"Temperature\")\n",
    "    top_p_slider = gr.Slider(0.1, 1.0, value=0.7, step=0.05, label=\"Top-p\")\n",
    "    max_tokens_slider = gr.Slider(32, 512, value=256, step=32, label=\"حداکثر توکن\")\n",
    "    submit_btn = gr.Button(\"تولید توضیحات\")\n",
    "    submit_btn.click(interface_fn, [image_input, question_box, temperature_slider, top_p_slider, max_tokens_slider], output_box)\n",
    "\n",
    "demo.launch()
"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
